#Import Libraries
import pandas as pd                             
import numpy as np                              
import matplotlib.pyplot as plt # For plotting
import seaborn as sns # For better visualization
from sklearn.preprocessing import StandardScaler # For normalizing features
from sklearn.cluster import KMeans # For KMeans clustering algorithm
from sklearn.decomposition import PCA # For dimensionality reduction
from sklearn.metrics import silhouette_score # For evaluating clustering performance
import plotly.express as px # For interactive plots

#Load data
df = pd.read_csv("/content/user_profiles_for_ads.csv")  # Load dataset from file
print(df.head()) # Show first 5 rows of the dataset

#DROP NON-USEFUL COLUMNS
df_cleaned = df.drop(columns=['User ID', 'Top Interests']) # Drop irrelevant columns for clustering

#ENCODE CATEGORICAL FEATURES 
df_encoded = pd.get_dummies(df_cleaned, drop_first=True) # Convert categorical data to numeric

#FEATURE SCALING
scaler = StandardScaler() # Create a scaler instance
scaled_features = scaler.fit_transform(df_encoded) # Normalize all features

#PCA FOR VISUALIZATION
pca = PCA(n_components=2) # Reduce dimensions to 2 for plotting
pca_components = pca.fit_transform(scaled_features) # Apply PCA
pca_df = pd.DataFrame(data=pca_components, columns=['PC1', 'PC2']) # Create DataFrame of PCA results

#DETERMINE OPTIMAL NUMBER OF CLUSTERS
wcss = [] # List to store Within-Cluster Sum of Suares
sil_scores = [] # List to store Silhouette Scores

# Try different clustrr sizes from 2 to 10
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42) # Initialize KMeans
    kmeans.fit(scaled_features) # Fit to scaled data
    wcss.append(kmeans.inertia_) # Save WCSS for elbow method
    sil_scores.append(silhouette_score(scaled_features, kmeans.labels_)) # Save silhouette score

# Plot WCSS to identify optimal number of clusters (elbow method)
plt.figure(figsize=(10, 5))
plt.plot(range(2, 11), wcss, marker='o')
plt.title('Elbow Method - WCSS vs. Number of Clusters')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.grid(True)
plt.show()

# Plot silhouette scores to evaluate clustering quality
plt.figure(figsize=(10, 5))
plt.plot(range(2, 11), sil_scores, marker='o', color='green')
plt.title('Silhouette Score vs. Number of Clusters')
plt.xlabel('Number of Clusters')
plt.ylabel('Silhouette Score')
plt.grid(True)
plt.show()

#FINAL CLUSTERING
optimal_clusters = 4 # Choose optimal number of clusters (e.g., 4)
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)  # Initialize final KMeans
df['Cluster'] = kmeans.fit_predict(scaled_features) # Add cluster labels to the original dataset

#CLUSTER VISUALIZATION
pca_df['Cluster'] = df['Cluster'] # Add cluster column to PCA DataFrame

# Create interactive 2D scatter plot using Plotly
fig = px.scatter(pca_df, x='PC1', y='PC2',
                 color=pca_df['Cluster'].astype(str),
                 title='User Segmentation using KMeans Clustering',
                 labels={'Cluster': 'User Segment'},
                 width=800, height=500)
fig.show() # Display interactive cluster plot

#CLUSTER PROFILING
cluster_profiles = df.groupby('Cluster').mean(numeric_only=True)  # Get average profile per cluster
print("Cluster Profiles:\n", cluster_profiles) # Display cluster summary
